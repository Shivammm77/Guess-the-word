{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivammm77/Guess-the-word/blob/main/Guessword.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHvFeW4NHFOE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import dataset, dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xlIXs2-6N8Vo"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# upload = files.upload()\n",
        "# import zipfile\n",
        "# path = \"/content/next_word.zip\"\n",
        "# ext_path  = \"/content/next_word\"\n",
        "# with zipfile.ZipFile(path , 'r') as f:\n",
        "#   f.extractall(ext_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux9uHhrMPTjc"
      },
      "outputs": [],
      "source": [
        "#  we seprate sentences\n",
        "# we just make output of evry next word of input first word\n",
        "# we are creating supervised task of unsupervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tyy2PD7PxGu"
      },
      "outputs": [],
      "source": [
        "# voab\n",
        "# index\n",
        "# dictonary {}\n",
        "# index to embedding\n",
        "# data preparation - supervised\n",
        "# model\n",
        "#  training loop\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYCTIlUkQNQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049a148c-0b18-4361-e7ab-46fed6354e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# !pip install nltk\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CIUDIiVQ-YE"
      },
      "outputs": [],
      "source": [
        "document = \"\"\"About Data Science Mentorship Program\n",
        "\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2.0)\n",
        "The total course fee for the DSMP course is Rs 10,600. This includes the fee for both DSMP 1.0 and DSMP 2.0\n",
        "\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is about 6-8 months.\n",
        "\n",
        "Are Deep Learning and NLP a part of the DSMP 2.0  course?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes, all our sessions are recorded, so even if you miss a session you can login into our portal and watch the recording as per your convenience.\n",
        "\n",
        "Where can I find the class schedule?\n",
        "You will find the class schedule in your course dashboard once you enroll for the course.\n",
        "\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "\n",
        "\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish.\n",
        "\n",
        "How will I be informed about the upcoming class?\n",
        "You will get mail from our side before every session once you enroll in the course.\n",
        "\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely. However, you’ll need to be consistent.\n",
        "\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program any time.\n",
        "\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you’re enrolled in the course, you will be able to see all the past content in your dashboard.\n",
        "\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "\n",
        "Will we do case studies in the program?\n",
        "Yes, there are 5 end to end case studies and multiple smaller projects.\n",
        "\n",
        "Do we offer any student discounts or promo codes?\n",
        "We do offer discounts on our courses a few times a year, and we announce them through our social media channels.\n",
        "\n",
        "On how many devices can I watch the videos simultaneously?\n",
        "You can watch the videos on one device at a time.\n",
        "\n",
        "\n",
        "\n",
        "Do you provide notes for the lectures?\n",
        "We do not provide notes for our lectures. We encourage students to make their own notes as it aids in study retention.\n",
        "\n",
        "What is the difference between being a paid member on your YouTube channel and your website?\n",
        "While the content on our YouTube channel and website is similar, enrolling through our website offers additional benefits such as doubt clearance support and access to an exclusive community of learners on Discord and more.\n",
        "\n",
        "Do I get access to your YouTube channel as a paid member after enrolling through your website?\n",
        "No, the YouTube channel membership is separate from what we offer on our website.\n",
        "\n",
        "Is there any upcoming batch for the Data Science Mentorship Program?\n",
        "Currently, we do not have any plans to launch a new batch for DSMP. However, all previous lectures are available as recordings, allowing you to learn at your own pace.\n",
        "\n",
        "Do you provide doubt clearance for the projects uploaded on CampusX YouTube channel?\n",
        "We do not provide doubt clearance for any of our videos or projects uploaded on YouTube. However, you can ask your doubts in our Discord channel or in the comments section.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Payment/Registration related questions\n",
        "\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "\n",
        "What if I don’t like the course after making the payment? What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment. To apply for refund, send us an email at support@campusx.in\n",
        "\n",
        "I am living outside India and I am not able to make the payment on the website. What should I do?\n",
        "You can contact us by sending a mail at support@campusx.in\n",
        "\n",
        "I am from Pakistan and I am unable to make the payment?\n",
        "We currently do not have the option to accept payment from Pakistan directly. If you’d still like to enroll for the course, you may ask a friend or family member living outside Pakistan to make the fee payment on your behalf.\n",
        "\n",
        "Do you accept PayPal as a payment method?\n",
        "Yes, we do. Please contact us at support@campusx.in for more details on using PayPal for payment.\n",
        "\n",
        "I cannot pay the DSMP 2.0 fee as a one-time payment, is there any way to make a payment in installments?\n",
        "At the moment, we do not have a monthly payment plan for the DSMP 2.0 course. However, if you have financial constraints, you can enroll in DSMP 1.0 by paying 799/- a month. Once you complete the course, you may apply for a discount coupon from the website.\n",
        "\n",
        "\n",
        "Post registration queries\n",
        "\n",
        "Till when can I view the paid videos on the website?\n",
        "You can watch the videos till your subscription is valid, that is 3 years from the date of purchase for DSMP 2.0 and 2 years for DSMP 1.0\n",
        "\n",
        "Why is lifetime validity not provided?\n",
        "Because of the low course fee.\n",
        "\n",
        "Do you assist with personal projects?\n",
        "We do not provide support for personal projects due to time constraints and current commitments.\n",
        "\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearing session.\n",
        "\n",
        "\n",
        "\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select “past week's doubt” in the doubt clearance google form.\n",
        "\n",
        "What is the validity of Doubt Support?\n",
        "You will get doubt support for 1 year from the data of registration.\n",
        "\n",
        "\n",
        "\n",
        "Certificate and Placement Assistance related queries\n",
        "\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 10,600\n",
        "You have to attempt all the course assessments.\n",
        "\n",
        "I have read that Job Preparation is a part of this program. What comes under Job Preparation?\n",
        "This is to clarify that Job Preparation does not mean Placement guarantee. We don't guarantee our learners any jobs or for that matter even interview calls. If you are planning to join this course just for placements, we’re afraid that this course might not be the best for you.\n",
        "\n",
        "Here is what comes under Job Preparation\n",
        "Portfolio Building sessions.\n",
        "Interview Questions.\n",
        "Sessions with industry mentors.\n",
        "Discussion on Job hunting strategies.\n",
        "\"\"\"\n",
        "# with open(\"/content/next_word/1661-0.txt\" , 'r') as f:\n",
        "#   document = f.read()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgn4l5krNyFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQx39rtgR3tj"
      },
      "outputs": [],
      "source": [
        "token = word_tokenize(document.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SfBWVdoR_Io",
        "outputId": "a9c1bcd3-deec-454e-92bd-408eea286806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# build vocab\n",
        "vocab = {'unk' : 0}\n",
        "for t in Counter(token).keys():\n",
        "   if t not  in vocab :\n",
        "      vocab[t] = len(vocab)\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLf60VwiSQxs"
      },
      "outputs": [],
      "source": [
        "# extract setences\n",
        "input_sent = document.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDvS9y8DUon6"
      },
      "outputs": [],
      "source": [
        "# sent to numerical index\n",
        "def word_to_index (sentence , vocab):\n",
        "  numerical_sent = []\n",
        "  for t in sentence :\n",
        "    if t in vocab :\n",
        "      numerical_sent.append(vocab[t])\n",
        "    else :\n",
        "      numerical_sent.append(vocab['unk'])\n",
        "  return   numerical_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYDXOfA7UFRa"
      },
      "outputs": [],
      "source": [
        "input_numeric_sent = []\n",
        "for sent in input_sent:\n",
        "  input_numeric_sent . append(word_to_index(word_tokenize(sent.lower()) , vocab))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK4ry6GRkklt",
        "outputId": "744d36bf-9d4b-4fb1-da87-a2439745905c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12311"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input :  1 3 4 5\n",
        "# outpu : 1,2,3,4,5,6#\n",
        "# input :  1 3 4\n",
        "# outpu : 1,2,3,4,5"
      ],
      "metadata": {
        "id": "f9B4McdklBZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequence = []\n",
        "for sent in input_numeric_sent:\n",
        "  for  i in range(1 , len(sent)):\n",
        "    train_sequence.append(sent[ :i+1])\n"
      ],
      "metadata": {
        "id": "j7-TYir7lUpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = [1,2,3,4,5,6]\n",
        "train[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCUNDUxSmxsC",
        "outputId": "151e91ca-d14d-4292-f79b-a7e0fa583313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  padding like we have diffrent list len in train_sequence so we are adding zeros\n",
        "\n",
        "len_list = []\n",
        "for s in train_sequence:\n",
        "  len_list.append(len(s))\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDfxaR2Hmo-q",
        "outputId": "2edaf221-78d5-40f1-e2bc-18dbbb4705fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding zeros doing padding\n",
        "padded_train_sequance = []\n",
        "for s in train_sequence:\n",
        "     padded_train_sequance.append([0]*(max(len_list)-len(s)) + s)\n",
        "# eg - len_list = 29\n",
        "#  s = [1,2]\n",
        "# padded_train_sequance = [0,0,0,0,0,0....0 ,1,2]"
      ],
      "metadata": {
        "id": "4ugT2USEoYAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# converrt it into tensor\n",
        "padded_train_sequance = torch.tensor(padded_train_sequance , dtype = torch.long)\n",
        "padded_train_sequance[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR1PJAjAqVJ-",
        "outputId": "758f6d95-6b10-4dd1-dcf3-a770afd1e4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  7,  8,  9, 10,\n",
              "        11,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i dont know why we did this\n",
        "x  = padded_train_sequance[: , :-1]\n",
        "y  = padded_train_sequance[: , -1]"
      ],
      "metadata": {
        "id": "QEOPRHZ9rKtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MoAQPq8rdVO",
        "outputId": "ba572c91-97fb-4772-ef73-537769e8b490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    0,    0,  ...,    0,    0,    2],\n",
              "        [   0,    0,    0,  ...,    0,    2,    3],\n",
              "        [   0,    0,    0,  ...,    2,    3,    4],\n",
              "        ...,\n",
              "        [   0,    0,    0,  ...,  121,  588, 1172],\n",
              "        [   0,    0,    0,  ...,  588, 1172,  417],\n",
              "        [   0,    0,    0,  ..., 1172,  417, 9112]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self , x ,y):\n",
        "    super().__init__()\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "  def __getitem__(self, idx) :\n",
        "      return self.x[idx] , self.y[idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "7Ujp8qQSrguv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(x,y)\n",
        "len(dataset)\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ_jWK5xsI7r",
        "outputId": "ebe7beff-0ff2-4de6-bb50-e81595a19436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1]),\n",
              " tensor(2))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset , batch_size=32 ,shuffle=True)\n",
        "\n",
        "x.shape\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "G-ZKWamcse6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Lstmmodel(nn.Module):\n",
        "  def __init__(self, vocab_size) :\n",
        "    super().__init__()\n",
        "    self.emebbding = nn.Embedding(vocab_size , 100)\n",
        "    self.lstm = nn.LSTM(100 , 150 , batch_first=True)\n",
        "    self.fc = nn.Linear(150 , vocab_size)\n",
        "\n",
        "  def forward(self , x):\n",
        "    embedd  = self.emebbding(x)\n",
        "    intermediate_hidden_state , (final_hidden_state , final_cell_state) =  self.lstm(embedd)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "vWScbpz2vIi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Lstmmodel(len(vocab))"
      ],
      "metadata": {
        "id": "VDsm2WoeBARF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "cxMZc52CCQRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbfyLfwVCarV",
        "outputId": "66b39e87-e788-4fff-97a2-99fd1feec509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lstmmodel(\n",
              "  (emebbding): Embedding(9399, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=9399, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters() , lr =lr)\n"
      ],
      "metadata": {
        "id": "2FvORyE1Cfpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for batch_x , batch_y in dataloader:\n",
        "    # btach_x , batch_y = batch_x.to(device), batch_y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch_x)\n",
        "    loss = criterion(output , batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss = total_loss + loss.item()\n",
        "  print(f\"Epoch : {epoch + 1} , Loss : {total_loss : .4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZksF3IgCwEd",
        "outputId": "8ee3df9d-b507-43e5-cbda-2d8130e8afc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 , Loss :  208.5182\n",
            "Epoch : 2 , Loss :  184.2201\n",
            "Epoch : 3 , Loss :  170.2968\n",
            "Epoch : 4 , Loss :  155.8450\n",
            "Epoch : 5 , Loss :  141.4491\n",
            "Epoch : 6 , Loss :  127.7376\n",
            "Epoch : 7 , Loss :  114.5826\n",
            "Epoch : 8 , Loss :  102.0459\n",
            "Epoch : 9 , Loss :  90.7861\n",
            "Epoch : 10 , Loss :  80.2487\n",
            "Epoch : 11 , Loss :  70.5333\n",
            "Epoch : 12 , Loss :  61.5038\n",
            "Epoch : 13 , Loss :  53.8374\n",
            "Epoch : 14 , Loss :  46.9143\n",
            "Epoch : 15 , Loss :  40.7958\n",
            "Epoch : 16 , Loss :  35.4512\n",
            "Epoch : 17 , Loss :  31.3443\n",
            "Epoch : 18 , Loss :  27.5053\n",
            "Epoch : 19 , Loss :  24.3897\n",
            "Epoch : 20 , Loss :  21.6568\n",
            "Epoch : 21 , Loss :  19.3483\n",
            "Epoch : 22 , Loss :  17.4470\n",
            "Epoch : 23 , Loss :  15.8485\n",
            "Epoch : 24 , Loss :  14.5074\n",
            "Epoch : 25 , Loss :  13.3528\n",
            "Epoch : 26 , Loss :  12.4106\n",
            "Epoch : 27 , Loss :  11.5928\n",
            "Epoch : 28 , Loss :  10.7921\n",
            "Epoch : 29 , Loss :  10.0556\n",
            "Epoch : 30 , Loss :  9.6168\n",
            "Epoch : 31 , Loss :  9.0423\n",
            "Epoch : 32 , Loss :  8.6423\n",
            "Epoch : 33 , Loss :  8.1911\n",
            "Epoch : 34 , Loss :  7.8798\n",
            "Epoch : 35 , Loss :  7.6023\n",
            "Epoch : 36 , Loss :  7.3339\n",
            "Epoch : 37 , Loss :  7.0944\n",
            "Epoch : 38 , Loss :  6.8162\n",
            "Epoch : 39 , Loss :  6.6554\n",
            "Epoch : 40 , Loss :  6.4560\n",
            "Epoch : 41 , Loss :  6.2937\n",
            "Epoch : 42 , Loss :  6.1081\n",
            "Epoch : 43 , Loss :  6.0574\n",
            "Epoch : 44 , Loss :  5.8696\n",
            "Epoch : 45 , Loss :  5.7201\n",
            "Epoch : 46 , Loss :  5.6740\n",
            "Epoch : 47 , Loss :  5.5395\n",
            "Epoch : 48 , Loss :  5.4322\n",
            "Epoch : 49 , Loss :  5.3573\n",
            "Epoch : 50 , Loss :  5.2805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model , vocab , text):\n",
        "  # tokenize\n",
        "  tokensize = word_tokenize(text.lower())\n",
        "  # print(tokensize)\n",
        "  # text - > number\n",
        "  numerical_text = word_to_index(tokensize , vocab)\n",
        "  # print(numerical_text)\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (56 - len(numerical_text)) + numerical_text , dtype = torch.long).unsqueeze(0)\n",
        "\n",
        " #  send to model\n",
        "  output = model(padded_text)\n",
        "  # predicted index\n",
        "  value , index= torch.max(output , dim =1)\n",
        "\n",
        "  #  merge with text\n",
        "  return text + \" \"+ list(vocab.keys())[index]"
      ],
      "metadata": {
        "id": "CgdjPDvhHaOV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model , vocab , \"i am \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OalVEbAKOooV",
        "outputId": "43bec9be-0f7f-4b25-c84f-4bafe0ce2f8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am  late'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1i42wIyCbGu",
        "outputId": "a54b3786-dc41-496d-d117-8202ccf309c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Guess-the-word'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# i = nn.Embedding(9399 , 100)\n",
        "# j = nn.LSTM(100 , 150 , batch_first=True)"
      ],
      "metadata": {
        "id": "3RvUiZGQ-lm6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = dataset[0][0].unsqueeze(0)"
      ],
      "metadata": {
        "id": "1AS5cVa--5Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b = i(a)"
      ],
      "metadata": {
        "id": "5GIfs7xs_GdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c ,d =j(b)\n",
        "# c = hiden sets\n",
        "# d= e, f\n",
        "# e = ct"
      ],
      "metadata": {
        "id": "uUjmFGjW_eOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dwk4qkX_2cd",
        "outputId": "1c1017c1-06b9-4203-e4ad-7a62bd037254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyM18Rm9Vgfd4yfRGNwIKHXy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}